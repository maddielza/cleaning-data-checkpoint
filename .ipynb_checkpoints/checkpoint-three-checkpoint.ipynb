{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
   },
   "source": [
    "# Checkpoint Three: Cleaning Data\n",
    "\n",
    "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
    "\n",
    "My dataset:\n",
    "\n",
    "Import the necessary libraries and create your dataframe(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "\n",
    "etf=pd.read_csv(\"ETFs.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
   },
   "source": [
    "## Missing Data\n",
    "\n",
    "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "etf=pd.read_csv(\"ETFs.csv\")\n",
    "etf.isnull()\n",
    "#null_count = etf.isnull().sum().sum()\n",
    "#null_count\n",
    "#etf.drop(etf.loc[:, 'quote_type':'currency'].columns, axis=1)\n",
    "#etf.drop(etf.loc[:, 'exchange_name':'exchange_timezone'].columns, axis=1)\n",
    "#etf.drop(etf.loc[:, 'fund_stdev_5years':'fund_treynor_ratio_10years'].columns, axis=1)\n",
    "etf.head()\n",
    "#etf_new = etf.drop(etf.columns.difference(['fund_symbol','fund_category','avg_vol_3month','week52_high_low_change_perc','inception_date','investment_type','fund_annual_report_net_expense_ratio']), 1, inplace=True)\n",
    "etf_df = etf_df[['fund_symbol','fund_category','avg_vol_3month','week52_high_low_change_perc','inception_date','investment_type','fund_annual_report_net_expense_ratio']]\n",
    "etf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
   },
   "source": [
    "## Irregular Data\n",
    "\n",
    "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "efed50ae-16f0-471d-98e2-632553a74c12"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "etf=pd.read_csv(\"ETFs.csv\")\n",
    "\n",
    "sns.boxplot(y=etf['avg_vol_3month'])\n",
    "sns.boxplot(y=etf['week52_high_low_change_perc'])\n",
    "#same outlier point for both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
   },
   "source": [
    "## Unnecessary Data\n",
    "\n",
    "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c"
   },
   "outputs": [],
   "source": [
    "#already deleted all unnecesary columns in the missing data section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
   },
   "source": [
    "## Inconsistent Data\n",
    "\n",
    "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "e9de6624-812a-43f8-8e20-93b4a49b091f"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "etf=pd.read_csv(\"ETFs.csv\")\n",
    "\n",
    "etf_df = etf[['fund_symbol','fund_category','avg_vol_3month','week52_high_low_change_perc','inception_date','investment_type','fund_annual_report_net_expense_ratio']]\n",
    "etf_df.head()\n",
    "etf_df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "dedc0bfe-17d0-40b2-914f-2ddb54f9ce0d"
   },
   "source": [
    "## Summarize Your Results\n",
    "\n",
    "Make note of your answers to the following questions.\n",
    "\n",
    "1. Did you find all four types of dirty data in your dataset? there are outliers but i'd expect that given the nature of the data\n",
    "2. Did the process of cleaning your data give you new insights into your dataset? yes, there was a significant amount of unnecessary data\n",
    "3. Is there anything you would like to make note of when it comes to manipulating the data and making visualizations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
